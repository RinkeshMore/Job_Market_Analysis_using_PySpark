{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be50e3c9",
   "metadata": {},
   "source": [
    "# Salary Prediction and Job Market Analysis\n",
    "### Create Spark Seesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a8cdee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# NOTE: Whichever package you want mention here.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell' \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4549d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# On yarn:\n",
    "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
    "# specify .master(\"yarn\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e033c",
   "metadata": {},
   "source": [
    "## Loading data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8341f17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+---------+-----------------+-----------------+-------------------+------+--------------------+--------------------+-------------+---------------+--------+---------+\n",
      "|Min_exp|Max_exp|  Min_sal|  Max_sal|        job_title|         location|               date|rating|        company_name|                role|industry_type|functional_area|emp_type|education|\n",
      "+-------+-------+---------+---------+-----------------+-----------------+-------------------+------+--------------------+--------------------+-------------+---------------+--------+---------+\n",
      "|    0.0|    1.0| 280838.0| 896847.0|android developer|          chennai|2023-05-23 00:00:00|   3.8|netaxis it soluti...|mobile app developer|           it|software and qa|fulltime| graduate|\n",
      "|    5.0|   10.0|1211702.0|9090683.0|android developer|      bhubaneswar|2023-05-17 00:00:00|   4.1|a and d recruitme...|mobile app developer|           it|software and qa|fulltime| graduate|\n",
      "|    3.0|    7.0| 804581.0|1440585.0|android developer|        bangalore|2023-04-30 00:00:00|   4.1|trh consultancy s...|mobile app developer|           it|software and qa|fulltime|      bca|\n",
      "|    2.0|    5.0| 566993.0|1032755.0|android developer|         hydrabad|2023-04-30 00:00:00|   4.1|itforte staffing ...|  back end developer|  recruitment|software and qa|fulltime| graduate|\n",
      "|    2.0|    3.0| 420896.0| 657056.0|android developer|        bengaluru|2023-04-30 00:00:00|   4.1|talent zone consu...|  back end developer|  recruitment|software and qa|fulltime| graduate|\n",
      "|    5.0|   10.0|1211702.0|9090683.0|android developer|          kolkata|2023-05-14 00:00:00|   3.6|ncr technosolutio...|  back end developer|      telecom|software and qa|fulltime|       be|\n",
      "|    2.0|    7.0| 175000.0| 300000.0|android developer|          kolkata|2023-05-06 00:00:00|   4.1|  webstar technology|mobile app developer|           it|software and qa|fulltime| graduate|\n",
      "|    4.0|    7.0| 971559.0|1635090.0|android developer|         itanagar|2023-04-30 00:00:00|   3.4|nisg national ins...|mobile app developer|           it|software and qa|fulltime|       be|\n",
      "|    1.0|    3.0| 313851.0| 562382.0|android developer|           indore|2023-04-30 00:00:00|   4.1|   weblogic solution|  back end developer|           it|software and qa|fulltime|       be|\n",
      "|    2.0|    7.0| 732275.0|1374309.0|android developer|         hydrabad|2023-04-30 00:00:00|   4.1|        aurochs tech|  back end developer|           it|software and qa|fulltime|       be|\n",
      "|    3.0|    5.0| 762220.0|6636065.0|android developer|           mumbai|2023-04-30 00:00:00|   3.9| destar technologies|  back end developer|           it|software and qa|fulltime|       be|\n",
      "|    3.0|    5.0| 762220.0|6636065.0|android developer|           mumbai|2023-04-30 00:00:00|   3.9| destar technologies|  back end developer|           it|software and qa|fulltime|       be|\n",
      "|    2.0|    3.0| 420896.0| 657056.0|android developer|        bangalore|2023-04-30 00:00:00|   5.0|teamplus staffing...|full stack developer|  recruitment|software and qa|fulltime| graduate|\n",
      "|    3.0|    5.0| 762220.0|6636065.0|android developer|           mumbai|2023-04-30 00:00:00|   3.9| destar technologies|  back end developer|           it|software and qa|fulltime|       be|\n",
      "|    2.0|    5.0| 566993.0|1032755.0|android developer|          chennai|2023-04-30 00:00:00|   4.4|genxlead retail p...|mobile app developer|     internet|software and qa|fulltime| graduate|\n",
      "|    1.0|    6.0| 385352.0| 881636.0|android developer|          gurgoan|2023-04-30 00:00:00|   4.1|itforte staffing ...|  back end developer|  recruitment|software and qa|fulltime| graduate|\n",
      "|    1.0|    3.0| 313851.0| 562382.0|android developer|           indore|2023-05-25 00:00:00|   4.1|aiminent it solut...|  back end developer|           it|software and qa|fulltime|      bca|\n",
      "|    2.0|    4.0| 300000.0| 700000.0|android developer|ghaziabadvaishali|2023-04-30 00:00:00|   4.5|kreate technologi...|mobile app developer|           it|software and qa|fulltime|       be|\n",
      "|    3.0|    8.0| 905247.0|2017871.0|android developer|        bengaluru|2023-04-30 00:00:00|   3.7|bharat light and ...|  back end developer|        power|software and qa|fulltime|       be|\n",
      "|    3.0|    5.0| 762220.0|6636065.0|android developer|         hydrabad|2023-04-30 00:00:00|   4.1|    windel solutions|  back end developer|           it|software and qa|fulltime|       be|\n",
      "+-------+-------+---------+---------+-----------------+-----------------+-------------------+------+--------------------+--------------------+-------------+---------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"file:///home/talentum/job_market_analysis/final_dataset.csv\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "56955c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61020"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d048518a",
   "metadata": {},
   "source": [
    "## Removing Outliers Using Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e656bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af3b7efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Limit for Min_exp: 10.963985340879805\n",
      "Lower Limit for Min_exp: -3.6754569895195965\n",
      "765\n"
     ]
    }
   ],
   "source": [
    "mean_exp = df.select(mean('Min_exp')).first()[0]\n",
    "std_exp = df.select(stddev('Min_exp')).first()[0]\n",
    "\n",
    "ul_Min_exp = mean_exp + 3 * std_exp\n",
    "print(\"Upper Limit for Min_exp:\", ul_Min_exp)\n",
    "ll_Min_exp = mean_exp - 3 * std_exp\n",
    "print(\"Lower Limit for Min_exp:\", ll_Min_exp)\n",
    "\n",
    "count_outside_range1 = df.filter((df.Min_exp > ul_Min_exp) | (df.Min_exp < ll_Min_exp)).count()\n",
    "print(count_outside_range1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0bfe8f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Limit for Max_exp: 16.640599003159547\n",
      "Lower Limit for Max_exp: -2.2240470529792775\n",
      "707\n"
     ]
    }
   ],
   "source": [
    "mean_exp1 = df.select(mean('Max_exp')).first()[0]\n",
    "std_exp1 = df.select(stddev('Max_exp')).first()[0]\n",
    "\n",
    "ul_Max_exp = mean_exp1 + 3 * std_exp1\n",
    "print(\"Upper Limit for Max_exp:\", ul_Max_exp)\n",
    "ll_Max_exp = mean_exp1 - 3 * std_exp1\n",
    "print(\"Lower Limit for Max_exp:\", ll_Max_exp)\n",
    "\n",
    "count_outside_range2 = df.filter((df.Max_exp > ul_Max_exp) | (df.Max_exp < ll_Max_exp)).count()\n",
    "print(count_outside_range2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab909801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Limit for Min_sal: 2355966.860132613\n",
      "Lower Limit for Min_sal: -576471.0076252387\n",
      "668\n"
     ]
    }
   ],
   "source": [
    "mean_sal = df.select(mean('Min_sal')).first()[0]\n",
    "std_sal = df.select(stddev('Min_sal')).first()[0]\n",
    "\n",
    "ul_Min_sal = mean_sal + 3 * std_sal\n",
    "print(\"Upper Limit for Min_sal:\", ul_Min_sal)\n",
    "ll_Min_sal = mean_sal - 3 * std_sal\n",
    "print(\"Lower Limit for Min_sal:\", ll_Min_sal)\n",
    "\n",
    "count_outside_range3 = df.filter((df.Min_sal > ul_Min_sal) | (df.Min_sal < ll_Min_sal)).count()\n",
    "print(count_outside_range3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f18c5d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Limit for Max_sal: 48290128.634865075\n",
      "Lower Limit for Max_sal: -42698630.21116793\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "mean_sal1 = df.select(mean('Max_sal')).first()[0]\n",
    "std_sal1 = df.select(stddev('Max_sal')).first()[0]\n",
    "\n",
    "ul_Max_sal = mean_sal1 + 3 * std_sal1\n",
    "print(\"Upper Limit for Max_sal:\", ul_Max_sal)\n",
    "ll_Max_sal = mean_sal1 - 3 * std_sal1\n",
    "print(\"Lower Limit for Max_sal:\", ll_Max_sal)\n",
    "\n",
    "count_outside_range4 = df.filter((df.Max_sal > ul_Max_sal) | (df.Max_sal < ll_Max_sal)).count()\n",
    "print(count_outside_range4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5514d744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59737"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame based on the outliers\n",
    "df = df.filter((df.Min_sal < ul_Min_sal) &\n",
    "               (df.Min_sal > ll_Min_sal) &\n",
    "               (df.Max_sal < ul_Max_sal) &\n",
    "               (df.Max_sal > ll_Max_sal) &\n",
    "               (df.Max_exp < ul_Max_exp) &\n",
    "               (df.Max_exp > ll_Max_exp) &\n",
    "               (df.Min_exp < ul_Min_exp) &\n",
    "               (df.Min_exp > ll_Min_exp))\n",
    "#df.show()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e8a7e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Min_exp: double, Max_exp: double, Min_sal: double, Max_sal: double, job_title: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_select=[\"Min_exp\",\"Max_exp\",\"Min_sal\",\"Max_sal\",\"job_title\"]\n",
    "new_df = df.select(columns_to_select)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f72a5e",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749368de",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8e7851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b444f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"job_title\", outputCol=\"job_titleIndex\")\n",
    "indexed_df = indexer.fit(new_df).transform(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bf3ec888",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(inputCol=\"job_titleIndex\", outputCol=\"job_title_vec\")\n",
    "encoded_df = encoder.transform(indexed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "93354bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0dfbeafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"Min_exp\", \"Max_exp\", \"job_title_vec\"], outputCol=\"features\")\n",
    "assembler= assembler.transform(encoded_df)\n",
    "#assembler.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b2619fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_df = assembler.select(\"features\", \"Min_sal\", \"Max_sal\", \"job_title_vec\")\n",
    "#assembler_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e913b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0591d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa40c2d",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor\n",
    "### Predicting Minimum Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "809600d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = assembler_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3dfa6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f266edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(featuresCol= \"features\",\n",
    "                          labelCol= \"Min_sal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78e7d388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressionModel (uid=DecisionTreeRegressor_b724c260f8cc) of depth 5 with 63 nodes"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model_min = dt.fit(train_data)\n",
    "dt_model_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3d43aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_min = dt_model_min.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d6c6d3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 160620.86541117053\n",
      "R-squared: 0.8447628828433194\n",
      "Adjusted R-squared: 0.8447237309852722\n",
      "Mean Absolute Error (MAE): 63941.41490599566\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Root Mean Squared Error\n",
    "evaluator_min = RegressionEvaluator(labelCol='Min_sal', metricName='rmse')\n",
    "rmse_min = evaluator_min.evaluate(pred_min)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse_min)\n",
    "# R-squared\n",
    "evaluator_min = RegressionEvaluator(labelCol='Min_sal', metricName='r2')\n",
    "r2_min = evaluator_min.evaluate(pred_min)\n",
    "print(\"R-squared:\", r2_min)\n",
    "# Adjusted R-squared\n",
    "feature_columns = ['Min_exp','Max_exp','job_title_index']\n",
    "n = test_data.count()\n",
    "p = len(feature_columns)\n",
    "adjusted_r2_min = 1 - ((1 - r2_min) * (n - 1)) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2_min)\n",
    "# Mean Absolute Error (MAE)\n",
    "evaluator_min = RegressionEvaluator(labelCol='Min_sal', metricName='mae')\n",
    "mae_min = evaluator_min.evaluate(pred_min)\n",
    "print(\"Mean Absolute Error (MAE):\", mae_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3baf96",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor\n",
    "### To predict Maximum Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e7b475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "dt1 = DecisionTreeRegressor(featuresCol= \"features\",\n",
    "                          labelCol= \"Max_sal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a785c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model_max = dt1.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7206a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressionModel (uid=DecisionTreeRegressor_e8a314bad3e6) of depth 5 with 61 nodes"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39d13590",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_max = dt_model_max.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c538b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 1026722.364590288\n",
      "R-squared: 0.8220122443565894\n",
      "Adjusted R-squared: 0.8219673546325935\n",
      "Mean Absolute Error (MAE): 439783.6837687601\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Root Mean Squared Error\n",
    "evaluator_max = RegressionEvaluator(labelCol='Max_sal', metricName='rmse')\n",
    "rmse_max = evaluator_max.evaluate(pred_max)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse_max)\n",
    "# R-squared\n",
    "evaluator_max = RegressionEvaluator(labelCol='Max_sal', metricName='r2')\n",
    "r2_max = evaluator_max.evaluate(pred_max)\n",
    "print(\"R-squared:\", r2_max)\n",
    "# Adjusted R-squared\n",
    "feature_columns = ['Min_exp','Max_exp','job_title_index']\n",
    "n = test_data.count()\n",
    "p = len(feature_columns)\n",
    "adjusted_r2_max = 1 - ((1 - r2_max) * (n - 1)) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2_max)\n",
    "# Mean Absolute Error (MAE)\n",
    "evaluator_max = RegressionEvaluator(labelCol='Max_sal', predictionCol='prediction', metricName='mae')\n",
    "mae_max = evaluator_max.evaluate(pred_max)\n",
    "print(\"Mean Absolute Error (MAE):\", mae_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c92173",
   "metadata": {},
   "source": [
    "## RandomForest Regressor\n",
    "### To predict Minimum Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ef6a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93619be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol= \"features\",\n",
    "                          labelCol= \"Min_sal\", numTrees=100, maxDepth=10, maxBins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e1c2388",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_min = rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cc28c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressionModel (uid=RandomForestRegressor_007ceb2f4c3a) with 100 trees"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae3ce02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_min1 = rf_model_min.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1473e0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 159677.58370815124\n",
      "R-squared: 0.8465808577829277\n",
      "Adjusted R-squared: 0.84654216443054\n",
      "Mean Absolute Error (MAE): 68936.19544843242\n"
     ]
    }
   ],
   "source": [
    "# Root Mean Squared Error\n",
    "evaluator_min1 = RegressionEvaluator(labelCol='Min_sal', metricName='rmse')\n",
    "rmse_min1 = evaluator_min1.evaluate(pred_min1)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse_min1)\n",
    "\n",
    "# R-squared\n",
    "evaluator_min1 = RegressionEvaluator(labelCol='Min_sal', metricName='r2')\n",
    "r2_min1 = evaluator_min1.evaluate(pred_min1)\n",
    "print(\"R-squared:\", r2_min1)\n",
    "\n",
    "# Adjusted R-squared\n",
    "feature_columns = ['Min_exp','Max_exp','job_title_index']\n",
    "n = test_data.count()\n",
    "p = len(feature_columns)\n",
    "adjusted_r2_min1 = 1 - ((1 - r2_min1) * (n - 1)) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2_min1)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "evaluator_min1 = RegressionEvaluator(labelCol='Min_sal', metricName='mae')\n",
    "mae_min1 = evaluator_min1.evaluate(pred_min1)\n",
    "print(\"Mean Absolute Error (MAE):\", mae_min1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20525f99",
   "metadata": {},
   "source": [
    "## RandomForest Regressor\n",
    "### To predict Maximum Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90193b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e3e41f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestRegressor(featuresCol= \"features\",labelCol= \"Max_sal\", numTrees=100, maxDepth=10, maxBins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0407c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_max = rf1.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "438eb634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressionModel (uid=RandomForestRegressor_6259c2e617dd) with 100 trees"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c47debd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_max1 = rf_model_max.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a608d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 1074690.6516684105\n",
      "R-squared: 0.8049926301757542\n",
      "Adjusted R-squared: 0.8049434479891655\n",
      "Mean Absolute Error (MAE): 611273.9062345586\n"
     ]
    }
   ],
   "source": [
    "# Root Mean Squared Error\n",
    "evaluator_max1 = RegressionEvaluator(labelCol='Max_sal', metricName='rmse')\n",
    "rmse_max1 = evaluator_max1.evaluate(pred_max1)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse_max1)\n",
    "\n",
    "# R-squared\n",
    "evaluator_max1 = RegressionEvaluator(labelCol='Max_sal', metricName='r2')\n",
    "r2_max1 = evaluator_max1.evaluate(pred_max1)\n",
    "print(\"R-squared:\", r2_max1)\n",
    "\n",
    "# Adjusted R-squared\n",
    "feature_columns = ['Min_exp','Max_exp','job_title_index']\n",
    "n = test_data.count()\n",
    "p = len(feature_columns)\n",
    "adjusted_r2_max1 = 1 - ((1 - r2_max1) * (n - 1)) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2_max1)\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "evaluator_max1 = RegressionEvaluator(labelCol='Max_sal', metricName='mae')\n",
    "mae_max1 = evaluator_max1.evaluate(pred_max1)\n",
    "print(\"Mean Absolute Error (MAE):\", mae_max1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6013b7",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "### Predicting Minimum Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ef604f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "735616b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lr = train_data.select(\"features\", \"Min_sal\")\n",
    "test_data_lr = test_data.select(\"features\")\n",
    "#test_data_lr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee74a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LinearRegression(featuresCol= \"features\" ,labelCol= \"Min_sal\",maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3cede13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_min = lr1.fit(train_data_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25e11519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_model_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e045169",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr_min = lr_model_min.transform(test_data_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3450d444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [122792.51872361587,41416.298824579244,1626.5750366436553,-9641.744706053543,18380.537543321523,-11031.205902297796,0.0,-56528.88026379408,13999.495912249646,11692.295256094467,-3460.887382564536,-15953.873757564334,-9409.211681869348,-45789.35641034676,5430.052505321413,-26549.28213728114,42261.32306726676,12121.64071538482,479.13898373579065,-4023.309427967243,7793.219702964808,5576.444262088067,-3252.280703511038,31367.389897759418,21924.59146155987,-1196.9297263374062,-34748.302824149985]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: %s\" % str(lr_model_min.coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d92b4167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 138157.8542294028\n"
     ]
    }
   ],
   "source": [
    "print(\"Intercept: %s\" % str(lr_model_min.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67be49b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary = lr_model_min.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a8a2c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 172343.634616\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e1aead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.817863\n"
     ]
    }
   ],
   "source": [
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ee4d7",
   "metadata": {},
   "source": [
    "### Predicting Maximum Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72fe120d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients for featuresCol: [223735.59774663305,246998.61345516934,-16516.003531065366,-11331.842418701004,172381.10825678645,12414.179730244077,0.0,-212341.59038507706,347973.00565761584,126554.24654270813,-1885.166652955076,114273.32035995391,41100.73076807818,-113065.8517955153,-67823.10952629537,-83220.53829886431,73906.02197476939,0.0,-110539.88859292121,81455.50608666237,46604.35260871954,335162.7930320419,-95441.45249334216,102276.94370749143,284939.40588623215,-335547.63751548727,-180649.07232905529]\n",
      "Intercept for labelCol: 100301.79321806037\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Create and train the Linear Regression model\n",
    "lr1 = LinearRegression(featuresCol=\"features\", labelCol=\"Max_sal\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model_max = lr1.fit(train_data)\n",
    "\n",
    "coefficients = lr_model_max.coefficients\n",
    "intercept = lr_model_max.intercept\n",
    "\n",
    "print(\"Coefficients for featuresCol: %s\" % str(coefficients))\n",
    "print(\"Intercept for labelCol: %s\" % str(intercept))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41f4dc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 172343.634616\n",
      "r2: 0.817863\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lr_model_min.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91cd3e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.regression.LinearRegressionTrainingSummary at 0x7f24c1adbd68>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359a242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
